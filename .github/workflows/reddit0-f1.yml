name: Collect Reddit F1 Data

on:
  schedule:
    - cron: '*/5 * * * *'

jobs:
  collect-data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install praw pandas

      - name: Collect Reddit F1 Data
        env:  
          CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          USERNAME: ${{ secrets.REDDIT_USERNAME }}
          PASSWORD: ${{ secrets.REDDIT_PASSWORD }}
          USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
        run: |
          import praw
          import pandas as pd
          from datetime import datetime
          import os

          reddit = praw.Reddit(
              client_id=os.environ['CLIENT_ID'],
              client_secret=os.environ['CLIENT_SECRET'],
              password=os.environ['PASSWORD'],
              user_agent=os.environ['USER_AGENT'],
              username=os.environ['USERNAME'],
          )

          subreddit = reddit.subreddit('formula1')
          posts_data = []

          for submission in subreddit.new(limit=1000):
              post_data = {
                  'unique_id': submission.id,
                  'post_heading': submission.title,
                  'tag': submission.link_flair_text,
                  'upvotes': submission.ups,
                  'comments': submission.num_comments,
                  'URL': submission.url,
                  'timestamp': datetime.utcfromtimestamp(submission.created_utc).strftime('%Y-%m-%d %H:%M:%S')
              }
              posts_data.append(post_data)

          # Create a DataFrame from the new data
          new_df = pd.DataFrame(posts_data)

          # Create a unique filename for the hourly CSV
          hourly_filename = f'Reddit/reddit_f1_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
          new_df.to_csv(hourly_filename, index=False)

          # Load or create the master CSV
          master_filename = 'Reddit/master_reddit_f1_data.csv'
          if os.path.exists(master_filename):
              master_df = pd.read_csv(master_filename)
          else:
              master_df = pd.DataFrame(columns=['unique_id', 'post_heading', 'tag', 'upvotes', 'comments', 
                                                 'URL', 'timestamp', '24_hour_popularity_upvote', 
                                                 '24_hour_popularity_comment'])

          # Update master DataFrame
          for index, row in new_df.iterrows():
              unique_id = row['unique_id']
              if unique_id in master_df['unique_id'].values:
                  # Update existing record
                  existing_row = master_df.loc[master_df['unique_id'] == unique_id].iloc[0]

                  # Calculate the popularity change
                  upvote_change = row['upvotes'] - existing_row['upvotes']
                  comment_change = row['comments'] - existing_row['comments']

                  # Update the master DataFrame
                  master_df.loc[master_df['unique_id'] == unique_id, 'upvotes'] = row['upvotes']
                  master_df.loc[master_df['unique_id'] == unique_id, 'comments'] = row['comments']
                  master_df.loc[master_df['unique_id'] == unique_id, '24_hour_popularity_upvote'] = upvote_change
                  master_df.loc[master_df['unique_id'] == unique_id, '24_hour_popularity_comment'] = comment_change
              else:
                  # Insert new record
                  new_row = {
                      'unique_id': row['unique_id'],
                      'post_heading': row['post_heading'],
                      'tag': row['tag'],
                      'upvotes': row['upvotes'],
                      'comments': row['comments'],
                      'URL': row['URL'],
                      'timestamp': row['timestamp'],
                      '24_hour_popularity_upvote': '',  # Blank for new records
                      '24_hour_popularity_comment': ''
                  }
                  master_df = master_df.append(new_row, ignore_index=True)

          # Save the updated master DataFrame
          master_df.to_csv(master_filename, index=False)

      - name: Upload CSV
        uses: actions/upload-artifact@v3
        with:
          name: reddit_f1_data
          path: Reddit/reddit_f1_data_*.csv  # Use wildcard to upload the latest hourly CSV

      - name: Upload Master CSV
        uses: actions/upload-artifact@v3
        with:
          name: master_reddit_f1_data
          path: Reddit/master_reddit_f1_data.csv
